{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bce55ad-c9e7-4265-95ca-fd53d1e2a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "import struct\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc7b27-dfd3-4711-99d0-673d03c75aa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "115bb5f8-e467-4e6b-9fc5-2728a87bca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                # transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Normalize((0.5), (0.5))])\n",
    "data = torchvision.datasets.MNIST('./data/',  transform=transform, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(data,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f25fcd85-7fd4-4861-a493-1304ccd5aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "for i, batch in enumerate(data_loader):\n",
    "    x, y = batch[0][0], batch[1].numpy()[0]\n",
    "    \n",
    "    if y not in all_data:\n",
    "        all_data.update({y:[x]})\n",
    "    else:\n",
    "        curr = all_data[y]\n",
    "        curr.append(x)\n",
    "        all_data.update({y:curr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b30f536-f32f-49c1-a41b-bcba03151fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {} \n",
    "\n",
    "for label in all_data:\n",
    "    test.update({label:all_data[label][0:1000]})\n",
    "    train.update({label:all_data[label][1000:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a4e21ee-beb0-48f2-bcd6-3e8bebdd4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_idxs = [0, 2, 4, 6, 8]\n",
    "odd_idxs = [1, 3, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b6b4da3-94ca-4751-83c7-6330a3546a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_train={} \n",
    "odd_train = {}\n",
    "even_test = {}\n",
    "odd_test = {} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14bfd6e5-d51d-4391-be15-33a2678b9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in all_data:\n",
    "    if label in odd_idxs:\n",
    "        odd_test.update({label:all_data[label][0:1000]})\n",
    "        odd_train.update({label:all_data[label][1000:]})\n",
    "    else:\n",
    "        even_test.update({label:all_data[label][0:1000]})\n",
    "        even_train.update({label:all_data[label][1000:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a387600-f712-4928-950b-1e462fe63d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "for label in train:\n",
    "    path = './data/train/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path) \n",
    "    if not os.path.exists(path + str(label) + '/'):\n",
    "        os.mkdir(path + str(label) + '/') \n",
    "    curr = train[label]\n",
    "    # print(curr)\n",
    "    for i, image in enumerate(curr):\n",
    "        # print(i)\n",
    "        save_image(image, path + str(label) + '/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f84df23-e3b4-4ffe-98ca-0378524718e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in test:\n",
    "    path = './data/test/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path) \n",
    "    if not os.path.exists(path + str(label) + '/'):\n",
    "        os.mkdir(path + str(label) + '/') \n",
    "    curr = test[label]\n",
    "    # print(curr)\n",
    "    for i, image in enumerate(curr):\n",
    "        # print(i)\n",
    "        save_image(image, path + str(label) + '/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c399c1a2-08a8-4fde-be15-2a6ea22e7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in even_test:\n",
    "    path = './data/eval/evens/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path) \n",
    "    if not os.path.exists(path + str(label) + '/'):\n",
    "        os.mkdir(path + str(label) + '/') \n",
    "    curr = even_test[label]\n",
    "    # print(curr)\n",
    "    for i, image in enumerate(curr):\n",
    "        # print(i)\n",
    "        save_image(image, path + str(label) + '/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdfe01cc-7b79-459a-a7ce-92e7112da957",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in odd_test:\n",
    "    path = './data/eval/odds/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path) \n",
    "    if not os.path.exists(path + str(label) + '/'):\n",
    "        os.mkdir(path + str(label) + '/') \n",
    "    curr = odd_test[label]\n",
    "    # print(curr)\n",
    "    for i, image in enumerate(curr):\n",
    "        # print(i)\n",
    "        save_image(image, path + str(label) + '/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28443eab-1656-47d6-b583-193c35cc52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in even_train:\n",
    "    path = './data/ext/evens/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path) \n",
    "    if not os.path.exists(path + str(label) + '/'):\n",
    "        os.mkdir(path + str(label) + '/') \n",
    "    curr = even_train[label]\n",
    "    # print(curr)\n",
    "    for i, image in enumerate(curr):\n",
    "        # print(i)\n",
    "        save_image(image, path + str(label) + '/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95008380-d905-4a4c-9c1c-fc3d36c93b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in odd_train:\n",
    "    path = './data/ext/odds/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path) \n",
    "    if not os.path.exists(path + str(label) + '/'):\n",
    "        os.mkdir(path + str(label) + '/') \n",
    "    curr = odd_train[label]\n",
    "    # print(curr)\n",
    "    for i, image in enumerate(curr):\n",
    "        # print(i)\n",
    "        save_image(image, path + str(label) + '/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46507c08-5d4b-464c-b348-75560c14747d",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87510c72-3f66-4684-83ed-188244c681ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "class Conv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "        super(Conv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\n",
    "    #overwrite the forward function for pruning\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "class Linear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Linear, self).__init__(in_features, out_features, bias)\n",
    "    #overwrite the forward function for pruning\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 =  Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                 Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 =  Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear =  Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def apply_mask(self, mask, sizing):\n",
    "        start = 0\n",
    "        copy_state = copy.deepcopy(self.state_dict())\n",
    "        segments = {}\n",
    "        for i in sizing:\n",
    "            base, seg_idx = i.split('_')[0], int(i.split('_')[1])\n",
    "            quart_size = int(copy_state[base].shape[1]/4)\n",
    "            end = start + sizing[i]\n",
    "            segment = np.round(mask[start:end])\n",
    "            index = np.where(segment == 0)\n",
    "            if seg_idx == 1:\n",
    "                copy_state[base].data[index, 0:quart_size] = 0\n",
    "                # print(\"------------\")\n",
    "                # print(copy_state[base].data.shape)\n",
    "                # print(copy_state[base].data[index].shape)\n",
    "                # print(copy_state[base].data[index, 0:quart_size].shape)\n",
    "            elif seg_idx == 2:\n",
    "                copy_state[base].data[index, quart_size:quart_size*2] = 0\n",
    "            elif seg_idx == 3:\n",
    "                copy_state[base].data[index, quart_size*2:quart_size*3] = 0\n",
    "\n",
    "            elif seg_idx == 4:\n",
    "                copy_state[base].data[index, quart_size*3:] = 0\n",
    "            if base not in segments:\n",
    "                segments.update({base:{seg_idx:index}})\n",
    "            else:\n",
    "                curr = segments[base]\n",
    "                curr.update({seg_idx:index})\n",
    "                segments.update({base:curr})\n",
    "            # else:\n",
    "\n",
    "            start = end\n",
    "\n",
    "        self.load_state_dict(copy_state)\n",
    "        self.segments = segments\n",
    "\n",
    "    def half(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            param.data = param.data.half()\n",
    "\n",
    "\n",
    "    def return_model_state(self):\n",
    "        return self.state_dict()\n",
    "\n",
    "    def revert_weights(self):\n",
    "        self.load_state_dict(self.weights_backup)\n",
    "        for name, param in self.named_parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def update_backup(self):\n",
    "        self.weights_backup = copy.deepcopy(self.state_dict())\n",
    "\n",
    "\n",
    "def Resnet(type_id, num_classes):\n",
    "    if(type_id==18):  net = ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
    "    if(type_id==34):  net = ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "    if(type_id==50):  net = ResNet(Bottleneck, [3, 4, 6, 3], num_classes)\n",
    "    if(type_id==101):  net = ResNet(Bottleneck, [3, 4, 23, 3], num_classes)\n",
    "    if(type_id==152):  net = ResNet(Bottleneck, [3, 8, 36, 3], num_classes)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2fbb9-bca8-4878-b243-8f7db9bf9d5a",
   "metadata": {},
   "source": [
    "# Define Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6cb92d-fd98-4986-9485-6c34bf2a16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model, extloader, evalloader, epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE_1)\n",
    "    lmbda = lambda epoch: 0.95\n",
    "    best_acc = 0\n",
    "    average_acc = 0\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optim, lr_lambda=lmbda)\n",
    "    best_state = None\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        acc_per_epoch = 0\n",
    "        for i, batch in enumerate(extloader):\n",
    "            optim.zero_grad()\n",
    "            x, y = batch[0].cuda(0), batch[1].cuda(0)\n",
    "            fx = model(x)\n",
    "            loss = criterion(fx.squeeze(), y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            x = x.cpu()\n",
    "            y = y.cpu()\n",
    "        acc_per_epoch = test_acc(model, evalloader)\n",
    "        scheduler.step()\n",
    "        if acc_per_epoch > best_acc:\n",
    "            best_acc = acc_per_epoch\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "        print('Epoch: ', epoch, 'Acc: ', acc_per_epoch)\n",
    "    return best_acc, best_state\n",
    "\n",
    "def test_acc(model, evalloader):\n",
    "    model.eval()\n",
    "    avg_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(evalloader):\n",
    "            x, y = data[0].cuda(0), data[1].cuda(0)\n",
    "            fx = model(x)\n",
    "            _, predicted = fx.max(1)\n",
    "            acc_per_batch = 100. * predicted.eq(y).sum().item() / y.size(0)\n",
    "            avg_acc += acc_per_batch\n",
    "    avg_acc = avg_acc/len(evalloader)\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c56340-9f9f-4c18-a792-8a6a78bfdeb1",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0683fb4-c961-4ffb-861a-2a261ed97209",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/train/'\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5))])\n",
    "dataset = datasets.ImageFolder(path, transform=transform)\n",
    "trainloader = DataLoader(dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "448e6385-4175-4ed4-8044-03b3413ed2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/test/'\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5))])\n",
    "dataset = datasets.ImageFolder(path, transform=transform)\n",
    "testloader = DataLoader(dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7660d8e5-f4ac-49ea-b5d7-db46fc683c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_1 = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "534be44e-6853-47f9-a522-198bda878f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(BasicBlock, [2, 2, 2, 2], 10)\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73104b30-988b-4518-a9d5-4cb316567f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Acc:  96.33386948529412\n",
      "Epoch:  1 Acc:  98.43347886029412\n",
      "Epoch:  2 Acc:  98.10259650735294\n",
      "Epoch:  3 Acc:  96.46426930147058\n",
      "Epoch:  4 Acc:  99.03664981617648\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "acc, model=finetune(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a32bc5b1-91ee-4da1-998a-07aba531e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/base.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab25ba-f676-4cba-b0bd-a443597b81c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
