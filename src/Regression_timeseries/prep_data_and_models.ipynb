{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7139133a-a74d-492a-8fcf-9c5f75764b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde5cea-2b4d-4c72-99bd-7fb0221b6c61",
   "metadata": {},
   "source": [
    "# Prep Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "758a5310-799b-4727-8c83-30e3d853de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \n",
    "\n",
    "wind = {}\n",
    "counter = 1\n",
    "for filename in os.listdir('./raw_data/'):\n",
    "    df = pd.read_csv('./raw_data/' + filename)\n",
    "    df = df.drop(columns=[ 'No', 'station'])\n",
    "    # print(df.head())\n",
    "    for val in df['wd'].to_numpy():\n",
    "        if val not in wind:\n",
    "            wind.update({val:counter})\n",
    "            counter += 1\n",
    "    # break\n",
    "\n",
    "# pd.read_csv('./raw_data/processed.cleveland.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1788fcfb-7b2d-442d-b595-da1a1471941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  hour  PM2.5  PM10   SO2   NO2     CO    O3  TEMP    PRES  \\\n",
      "0  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  77.0  -0.7  1023.0   \n",
      "1  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  77.0  -1.1  1023.2   \n",
      "2  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  73.0  -1.1  1023.5   \n",
      "3  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  72.0  -1.4  1024.5   \n",
      "4  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  72.0  -2.0  1025.2   \n",
      "\n",
      "   DEWP  RAIN  wd  WSPM  \n",
      "0 -18.8   0.0   1   4.4  \n",
      "1 -18.2   0.0   2   4.7  \n",
      "2 -18.2   0.0   1   5.6  \n",
      "3 -19.4   0.0   3   3.1  \n",
      "4 -19.5   0.0   2   2.0  \n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('./raw_data/'):\n",
    "    df = pd.read_csv('./raw_data/' + filename)\n",
    "    df = df.drop(columns=['No', 'station'])\n",
    "    df = df.replace({\"wd\": wind})\n",
    "    print(df.head())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d84f9b3f-fc2b-4694-a709-960209584d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_keys = ['No', 'station', 'PM10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8fb1fad-0413-419e-8468-b5c81e0d3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mins = {}\n",
    "\n",
    "for filename in os.listdir('./raw_data/'):\n",
    "    df = pd.read_csv('./raw_data/' + filename)\n",
    "    df = df.drop(columns=drop_keys)\n",
    "    df = df.replace({\"wd\": wind})\n",
    "    \n",
    "    for key in df.keys():\n",
    "        maximum = df[key].max()\n",
    "        minimum = df[key].min()\n",
    "        if key not in max_mins:\n",
    "            max_mins.update({key:{'max':-1*np.inf, 'min':np.inf}})\n",
    "            if maximum > max_mins[key]['max']:\n",
    "                curr_min = max_mins[key]['min']\n",
    "                max_mins.update({key:{'max':maximum, 'min':curr_min}})\n",
    "            if minimum < max_mins[key]['min']:\n",
    "                curr_max = max_mins[key]['max']\n",
    "                max_mins.update({key:{'max':curr_max, 'min':minimum}})\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced20dd9-69d8-4d43-bd1b-1b3ced8730ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "83f57a0a-85a7-47c6-8641-49ba7278eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "test_data = {}\n",
    "\n",
    "sequence_length = 10\n",
    "\n",
    "for filename in os.listdir('./raw_data/'):\n",
    "    df = pd.read_csv('./raw_data/' + filename)\n",
    "    df = df.drop(columns=drop_keys)\n",
    "    df = df.replace({\"wd\": wind})\n",
    "    # df['wd'] -= 500\n",
    "    for key in df.keys():\n",
    "        if key != 'PM2.5':\n",
    "            df[key] -= max_mins[key]['min']\n",
    "            df[key] /= (max_mins[key]['max'] - max_mins[key]['min'])\n",
    "    df = df.dropna()\n",
    "    # print(df.head())\n",
    "    df = df.to_numpy()\n",
    "\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(df.shape[0]-sequence_length-1):\n",
    "        x.append(df[i:i+sequence_length, [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]])\n",
    "        y.append(df[i+1:i+sequence_length+1, 4])\n",
    "        \n",
    "    x = np.array(x) \n",
    "    y = np.array(y)\n",
    "    # print(x.shape)\n",
    "    # print(y.shape)\n",
    "    place_name = filename.split('_')[2]\n",
    "    test_data.update({place_name:{'x':x[0:2000], 'y':y[0:2000]}})\n",
    "    train_data.update({place_name:{'x':x[2000:], 'y':y[2000:]}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6fe20b43-cdba-446e-9eec-3356251c2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/air_train_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "006758f6-d63c-4141-b22d-f5f5730702cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/air_test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905f234-ba89-45a5-9a57-98e839c2cdce",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "00d894dd-3100-4b5e-96f7-1bec375be2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=14, hidden_size=128, num_layers=2, bidirectional=True, dropout=0.3, batch_first=True)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.out_layer = nn.Linear(256, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(4, batch_size, 128).requires_grad_().cuda()\n",
    "        c0 = torch.zeros(4, batch_size, 128).requires_grad_().cuda()\n",
    "        output, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        return self.out_layer(self.act1(output))\n",
    "    \n",
    "    def apply_mask(self, mask, sizing):\n",
    "        start = 0\n",
    "        copy_state = copy.deepcopy(self.state_dict())\n",
    "        segments = {}\n",
    "        for i in sizing:\n",
    "            end = start + sizing[i]\n",
    "            segment = np.round(mask[start:end])\n",
    "            index = np.where(segment == 0)\n",
    "            copy_state[i].data[index] = 0\n",
    "            start = end\n",
    "        self.load_state_dict(copy_state)\n",
    "\n",
    "def count_active_params(state_dict):\n",
    "    total = 0\n",
    "    for i in state_dict:\n",
    "        flattened = torch.flatten(state_dict[i])\n",
    "        total += torch.count_nonzero(flattened)\n",
    "    return total\n",
    "\n",
    "def size_mask(state_dict):\n",
    "    total = 0\n",
    "    mask_sizing = OrderedDict()\n",
    "    for i in list(state_dict.keys()):\n",
    "        shape = state_dict[i].shape\n",
    "        if len(shape) > 1:\n",
    "            if 'out' not in i:\n",
    "                size1 = shape[0]\n",
    "                total += size1\n",
    "                mask_sizing.update({i:int(size1)})\n",
    "                # mask_sizing.update({i+'__2':int(size1)})\n",
    "                # mask_sizing.update({i+'__3':int(size1)})\n",
    "                # mask_sizing.update({i+'__4':int(size1)})\n",
    "                # mask_sizing.update({i+'__5':int(size1)})\n",
    "                    # print(list(shape))\n",
    "    print(total)\n",
    "    return mask_sizing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "56439ea5-d6e7-47fb-b79b-8f46a5155593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lstm.weight_ih_l0', 512),\n",
       "             ('lstm.weight_hh_l0', 512),\n",
       "             ('lstm.weight_ih_l0_reverse', 512),\n",
       "             ('lstm.weight_hh_l0_reverse', 512),\n",
       "             ('lstm.weight_ih_l1', 512),\n",
       "             ('lstm.weight_hh_l1', 512),\n",
       "             ('lstm.weight_ih_l1_reverse', 512),\n",
       "             ('lstm.weight_hh_l1_reverse', 512)])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Model()\n",
    "size_mask(test.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8069fee-fb7f-4200-8633-1020b0847410",
   "metadata": {},
   "source": [
    "# Define Train/Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "11c60837-5377-4f19-9bc9-23c5177310cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda:0'\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "def train_loop(model, \n",
    "               trainloader, \n",
    "               criterion, \n",
    "               optim):\n",
    "    '''\n",
    "    Basic training loop. \n",
    "    '''\n",
    "    average_loss = 0\n",
    "    for i, batch in enumerate(trainloader):\n",
    "        optim.zero_grad()\n",
    "        x, y = batch[0].float().to(DEVICE), batch[1].float().to(DEVICE)\n",
    "        x, y = Variable(x), Variable(y)\n",
    "        fx = model(x)\n",
    "        loss = torch.sqrt(criterion(fx.squeeze(), y))\n",
    "        loss.backward()\n",
    "        average_loss += loss.detach().item() \n",
    "        \n",
    "        optim.step()\n",
    "        x = x.cpu()\n",
    "        y = y.cpu()\n",
    "    return average_loss/len(trainloader)\n",
    "\n",
    "def test_loop(model, \n",
    "              testloader, \n",
    "              criterion):\n",
    "    '''\n",
    "    \n",
    "    Basic evaluation, to be run after every training loop.\n",
    "    \n",
    "    '''\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(testloader):\n",
    "            x, y = batch[0].float().to(DEVICE), batch[1].float().to(DEVICE)\n",
    "            x, y = Variable(x), Variable(y)\n",
    "            fx = model(x)\n",
    "            \n",
    "            loss = torch.sqrt(criterion(fx.squeeze(), y))\n",
    "            total_loss += loss.detach().item() \n",
    "            \n",
    "            x = x.cpu()\n",
    "            y = y.cpu()\n",
    "    return total_loss/len(testloader)\n",
    "            \n",
    "def finetune(model, \n",
    "             trainloader, \n",
    "             testloader, \n",
    "             epochs=20, \n",
    "             lr=0.005, \n",
    "             lmbda=0.99):\n",
    "    '''\n",
    "    \n",
    "    Run train and test loops in order, control LR scheduling, keep track of all\n",
    "    metrics. \n",
    "    \n",
    "    '''\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-1)\n",
    "    model = model.to(DEVICE)\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model_states = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # perhaps you dislike the built-in LR schedulers, and would like a straightforward means to do your own?\n",
    "        # this condition can be replaced with something reasonable or something intensely weird but we'll stick\n",
    "        # with basic multiplicative lr\n",
    "        for g in optim.param_groups:\n",
    "            g['lr'] = (lmbda**(epoch+1))*lr\n",
    "            \n",
    "        train_loss = train_loop(model, \n",
    "                               trainloader, \n",
    "                               criterion, \n",
    "                               optim)\n",
    "        \n",
    "        val_loss = test_loop(model, \n",
    "                              testloader, \n",
    "                              criterion)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss) \n",
    "        model_states.append(copy.deepcopy(model.state_dict()))\n",
    "        \n",
    "        print('Epoch: {}, Train Loss: {:.3f}, Val Loss: {:.3f}'.format(epoch, train_loss, val_loss), end=\"\")\n",
    "        print('\\n')\n",
    "        print('------------')\n",
    "    \n",
    "    return train_losses, val_losses, model_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523f1b0-64d6-422e-84a9-43f9134731ac",
   "metadata": {},
   "source": [
    "# Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ed452ed4-f5be-493f-87ef-ecdd56f1d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(data_dict, batchsize):\n",
    "    x = None\n",
    "    y = None\n",
    "    for place in data_dict:\n",
    "        if x is None:\n",
    "            x = data_dict[place]['x']\n",
    "            y = data_dict[place]['y']\n",
    "        else:\n",
    "            x = np.concatenate((x, data_dict[place]['x']), axis=0)\n",
    "            y = np.concatenate((y, data_dict[place]['y']), axis=0)\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    data_gen = TensorDataset(x, y)\n",
    "    dataloader = DataLoader(data_gen, batch_size=batchsize, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e463c-0546-467c-80f5-5d89da20897d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4c2b04fc-f10c-4209-baa1-444b73a61185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([359635, 10, 14])\n",
      "torch.Size([359635, 10])\n",
      "torch.Size([24000, 10, 14])\n",
      "torch.Size([24000, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model = model.to('cuda:0')\n",
    "trainloader = load_all(train_data, 512)\n",
    "testloader = load_all(test_data, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a41557-7d83-43e8-be71-7e642877029c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d9725f08-2c48-46e9-9d87-b044657b33bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 81.958, Val Loss: 74.516\n",
      "\n",
      "------------\n",
      "Epoch: 1, Train Loss: 55.940, Val Loss: 47.883\n",
      "\n",
      "------------\n",
      "Epoch: 2, Train Loss: 36.818, Val Loss: 45.268\n",
      "\n",
      "------------\n",
      "Epoch: 3, Train Loss: 33.220, Val Loss: 47.054\n",
      "\n",
      "------------\n",
      "Epoch: 4, Train Loss: 31.490, Val Loss: 42.619\n",
      "\n",
      "------------\n",
      "Epoch: 5, Train Loss: 29.825, Val Loss: 43.572\n",
      "\n",
      "------------\n",
      "Epoch: 6, Train Loss: 28.694, Val Loss: 46.292\n",
      "\n",
      "------------\n",
      "Epoch: 7, Train Loss: 27.759, Val Loss: 44.152\n",
      "\n",
      "------------\n",
      "Epoch: 8, Train Loss: 27.212, Val Loss: 44.461\n",
      "\n",
      "------------\n",
      "Epoch: 9, Train Loss: 26.606, Val Loss: 44.040\n",
      "\n",
      "------------\n",
      "Epoch: 10, Train Loss: 26.270, Val Loss: 44.122\n",
      "\n",
      "------------\n",
      "Epoch: 11, Train Loss: 25.910, Val Loss: 43.562\n",
      "\n",
      "------------\n",
      "Epoch: 12, Train Loss: 25.590, Val Loss: 42.940\n",
      "\n",
      "------------\n",
      "Epoch: 13, Train Loss: 25.495, Val Loss: 42.953\n",
      "\n",
      "------------\n",
      "Epoch: 14, Train Loss: 25.103, Val Loss: 41.466\n",
      "\n",
      "------------\n",
      "Epoch: 15, Train Loss: 24.945, Val Loss: 44.716\n",
      "\n",
      "------------\n",
      "Epoch: 16, Train Loss: 24.973, Val Loss: 42.842\n",
      "\n",
      "------------\n",
      "Epoch: 17, Train Loss: 24.702, Val Loss: 45.458\n",
      "\n",
      "------------\n",
      "Epoch: 18, Train Loss: 24.421, Val Loss: 43.153\n",
      "\n",
      "------------\n",
      "Epoch: 19, Train Loss: 24.183, Val Loss: 41.147\n",
      "\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, model_states = finetune(model, \n",
    "                                                 trainloader, \n",
    "                                                 testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818967b9-5c03-4ada-b5d2-40ce70745a36",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f71be9eb-5184-4f0b-8039-36c2fbd53739",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_states[-1], './models/base.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23bb276-218b-423d-964f-a97cb013bd7b",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f07c4b29-dfe1-463f-a453-d44631ebd359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000e+02,\n",
      "          9.8778001964092254638671875000000000000000000000000000000000000000000000000000000000000000000000000000e-02,\n",
      "          4.6121913939714431762695312500000000000000000000000000000000000000000000000000000000000000000000000000e-02,\n",
      "          1.9444444775581359863281250000000000000000000000000000000000000000000000000000000000000000000000000000e-01,\n",
      "          1.3121211528778076171875000000000000000000000000000000000000000000000000000000000000000000000000000000e-01,\n",
      "          4.2238882742822170257568359375000000000000000000000000000000000000000000000000000000000000000000000000e-03,\n",
      "          3.9441534876823425292968750000000000000000000000000000000000000000000000000000000000000000000000000000e-01,\n",
      "          2.0855614542961120605468750000000000000000000000000000000000000000000000000000000000000000000000000000e-01,\n",
      "          5.4545456171035766601562500000000000000000000000000000000000000000000000000000000000000000000000000000e-01,\n",
      "          0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000e+00,\n",
      "          5.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000e-01,\n",
      "          3.5714287310838699340820312500000000000000000000000000000000000000000000000000000000000000000000000000e-02]]])\n",
      "tensor(99., dtype=torch.float64)\n",
      "tensor([[[103.3317413330078125000000000000000000000000000000000000000000000000000000000000000000000000000000000000]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(testloader):\n",
    "    torch.set_printoptions(precision=100)\n",
    "    print(batch[0][0][0].float().unsqueeze(0).unsqueeze(1))\n",
    "    print(batch[1][0][0])\n",
    "    # x.cuda()\n",
    "    # batch[0].cuda()\n",
    "    print(model(batch[0][0][0].float().unsqueeze(0).unsqueeze(1).cuda()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e27c9-2d81-4e46-a47a-5a2d162d6cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
