{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44be65da-636e-4ece-950a-d567a9d7e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100Config, M2M100ForConditionalGeneration, M2M100Tokenizer, M2M100Model\n",
    "from datasets import load_metric\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import tqdm\n",
    "import time\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f2a626-ac85-40ee-8bd8-f18c8e6c63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "        self.weights_backup = copy.deepcopy(self.model.state_dict())\n",
    "        \n",
    "        self.tokenizers = {'cs': M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", \n",
    "                                                            src_lang='cs',\n",
    "                                                            tgt_lang=\"en\", \n",
    "                                                            padding_side='right', \n",
    "                                                            truncation_side='right'), \n",
    "                           'de':M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", \n",
    "                                                            src_lang='de',\n",
    "                                                            tgt_lang=\"en\", \n",
    "                                                            padding_side='right', \n",
    "                                                            truncation_side='right')}\n",
    "\n",
    "    def forward_eval(self, batch, lang_code):\n",
    "        return self.model.generate(**batch['x'], forced_bos_token_id=self.tokenizers[lang_code].get_lang_id(\"en\"))\n",
    "    \n",
    "    def forward_train(self, batch):\n",
    "        return self.model(**batch['x'], labels=batch['y']) \n",
    "        \n",
    "    def apply_mask(self, mask, sizing):\n",
    "        start = 0\n",
    "        copy_state = copy.deepcopy(self.model.state_dict())\n",
    "        segments = {}\n",
    "        for i in copy_state:\n",
    "            if i in sizing:\n",
    "                end = start + sizing[i]\n",
    "                segment = np.round(mask[start:end])\n",
    "                index = np.where(segment == 0)\n",
    "                \n",
    "                final_indices = []\n",
    "                divisor = int(copy_state[i].shape[0]/sizing[i])\n",
    "                for j in index[0]:\n",
    "                    final_indices += [*range(j*divisor, (j*divisor)+divisor)]\n",
    "                # print(final_indices)\n",
    "                copy_state[i].data[np.array(final_indices)] = 0\n",
    "                segments.update({i:index})\n",
    "                start = end\n",
    "        self.model.load_state_dict(copy_state)\n",
    "        # for name, param in self.model.named_parameters():\n",
    "        #     if name in segments:\n",
    "        #         param.data[segments[name]].requires_grad = False\n",
    "        #         start = end\n",
    "\n",
    "    def return_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def return_model_state(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def revert_weights(self):\n",
    "        self.model.load_state_dict(self.weights_backup)\n",
    "        for name, param in self.model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def update_backup(self):\n",
    "        self.weights_backup = copy.deepcopy(self.model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c46935-6812-4ec6-8363-491632958266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_mask(state_dict):\n",
    "    total = 0\n",
    "    mask_sizing = OrderedDict()\n",
    "    total_params = 0\n",
    "    total_considered = 0\n",
    "    uniques = set()\n",
    "    size = 0\n",
    "    for i in list(state_dict.keys()):\n",
    "        shape = torch.tensor(state_dict[i].shape)\n",
    "        total_params += torch.prod(shape)\n",
    "        uniques.add(state_dict[i])\n",
    "        # print(state_dict[i][0].type())\n",
    "        if 'bias' not in i and 'embed' not in i and 'norm' not in i and 'shared' not in i and 'head' not in i:\n",
    "            # print('------')\n",
    "            # print(i)\n",
    "            # print(shape)\n",
    "            if shape[0] == 4096:\n",
    "                total += 1024\n",
    "                mask_sizing.update({i:1024})\n",
    "            else:\n",
    "                total += 256\n",
    "                mask_sizing.update({i:256})\n",
    "            total_considered += torch.prod(shape)\n",
    "        # else:\n",
    "        #     if 'embed' in i or 'shared' in i or 'head' in i:\n",
    "        #         print('------')\n",
    "        #         print(i)\n",
    "        #         print(shape)\n",
    "        #         print(state_dict[i])\n",
    "    print(total_params)\n",
    "    print(total_considered)\n",
    "    print(total)\n",
    "    return mask_sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430f535f-a46f-4689-ad73-6271492e7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_active_params(state_dict):\n",
    "    total = 0\n",
    "    for i in state_dict:\n",
    "        flattened = torch.flatten(state_dict[i])\n",
    "        total += torch.count_nonzero(flattened)\n",
    "    return total.detach().item()\n",
    "\n",
    "class Custom_Dataloader:\n",
    "    def __init__(self, data, batch_size):\n",
    "        \n",
    "        self.data = data \n",
    "        self.data_amount = data['x']['input_ids'].shape[0]\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = int(math.ceil(self.data_amount/batch_size))\n",
    "        self.available = set([*range(self.length)])\n",
    "        \n",
    "        \n",
    "    def select_subset(self, idxs, data, cuda):\n",
    "        if cuda:\n",
    "            return {'x':{'input_ids': data['x']['input_ids'][idxs].cuda(), \n",
    "                         'attention_mask': data['x']['attention_mask'][idxs].cuda()}, \n",
    "                    'y':data['y'][idxs].cuda()}\n",
    "        \n",
    "    def sample_batch(self, cuda=True):\n",
    "        \n",
    "        if len(self.available)==0:\n",
    "            self.available = set([*range(self.length)])\n",
    "        idx = random.choice(tuple(self.available))\n",
    "        self.available.remove(idx) \n",
    "        start = idx*self.batch_size\n",
    "        if idx == self.length-1:\n",
    "            diff = self.data_amount - (idx*self.batch_size)\n",
    "            batch = self.select_subset([i for i in range(start,start+diff)], self.data, cuda)\n",
    "            return batch\n",
    "        else: \n",
    "            batch = self.select_subset([i for i in range(start,start+self.batch_size)], self.data, cuda)\n",
    "            return batch\n",
    "        \n",
    "    def reset(self):\n",
    "        self.history = set()\n",
    "        self.available = set([*range(self.data_amount)])\n",
    "        \n",
    "def dual_sample(ds1_batch, ds2_batch):\n",
    "    perm = torch.randperm(len(ds1_batch['x']['input_ids'])*2)\n",
    "    x_input_ids = torch.cat((ds1_batch['x']['input_ids'], ds2_batch['x']['input_ids']), 0)\n",
    "    x_attention_masks = torch.cat((ds1_batch['x']['attention_mask'], ds2_batch['x']['attention_mask']), 0)\n",
    "    y = torch.cat((ds1_batch['y'], ds2_batch['y']))\n",
    "    \n",
    "    return {'x':{'input_ids': x_input_ids[perm], \n",
    "                 'attention_mask': x_attention_masks[perm]},\n",
    "            'y':y[perm]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0476f563-ac41-4cfd-9246-bfa8ed4dc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "def train_loop(model, \n",
    "               mask,\n",
    "               mask_sizing,\n",
    "              lang1_train_dataloader, \n",
    "              lang1_test_dataloader, \n",
    "              epochs, lang_code, model_idx,\n",
    "              steps=300):\n",
    "\n",
    "    optim= Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
    "#     optim = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "\n",
    "#     lmbda = lambda epoch: 0.99\n",
    "#     scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optim, lr_lambda=lmbda)\n",
    "\n",
    "    # optim = torch.optim.AdamW(model.parameters(), lr=0.00002)\n",
    "    # lmbda = lambda epoch: 0.99\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optim, lr_lambda=lmbda)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    saved_state = None\n",
    "    \n",
    "    delay = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad is False:\n",
    "                param.requires_grad =  True\n",
    "                \n",
    "        loss = test_loss(model, lang1_test_dataloader)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        loss = loss.detach().item()\n",
    "        best_loss = loss\n",
    "        # scheduler.step()\n",
    "\n",
    "        print('\\n Starting Loss: ', loss, ', Lang Code: ', lang_code, ', Model: ', str(model_idx))\n",
    "        \n",
    "        train(model, \n",
    "              mask, mask_sizing,\n",
    "              lang1_train_dataloader, \n",
    "              optim, \n",
    "              steps, epoch)\n",
    "        \n",
    "        # scheduler.step()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        loss = test_loss(model, lang1_test_dataloader)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        loss = loss.detach().item()\n",
    "        \n",
    "        # scheduler.step()\n",
    "\n",
    "        print('\\n Best Averaged Loss: ', loss, ', Lang Code: ', lang_code, ', Model: ', str(model_idx))\n",
    "        \n",
    "        \n",
    "        if loss < best_loss:\n",
    "            delay = 0\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), './MFEA/final_models/'+lang_code+'_'+str(model_idx)+'.pth')\n",
    "            \n",
    "        delay += 1\n",
    "        \n",
    "        if delay == 10:\n",
    "            print('Training ended early: 10 Epochs: No improvement')\n",
    "            break\n",
    "\n",
    "        \n",
    "def train(model, \n",
    "          mask, mask_sizing,\n",
    "          lang1_train_dataloader, \n",
    "          optim, \n",
    "          steps, epoch):\n",
    "    optim.zero_grad()\n",
    "    for i in range(steps):\n",
    "        batch = lang1_train_dataloader.sample_batch()\n",
    "        loss = model.forward_train(batch).loss\n",
    "        loss.backward()\n",
    "        print('\\rEpoch {:.3f}\\tBatch: {:.3f}, Loss: {:.3f}'.format(epoch, \n",
    "                                                                   i, \n",
    "                                                                   loss.detach().item()), \n",
    "              end=\"\")\n",
    "        if (i+1)%30 == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            model.apply_mask(mask, mask_sizing)\n",
    "\n",
    "def convert_to_string(tokens, test_code):\n",
    "    prohib = [1, 2, 128022, 128020, 128017]\n",
    "    if test_code:\n",
    "        return [' '.join([str(i) for i in tokens.tolist() if i not in prohib])]\n",
    "    else:\n",
    "        return ' '.join([str(i) for i in tokens.tolist() if i not in prohib])\n",
    "\n",
    "def stringify(tokens, test_code):\n",
    "    return [convert_to_string(tokens[i], test_code) for i in range(tokens.shape[0])]\n",
    "\n",
    "def test_BLEU(model, test_dataloader, metric, lang_code):\n",
    "    start = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_refs = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_dataloader.length):\n",
    "            batch = test_dataloader.sample_batch()\n",
    "            preds = model.forward_eval(batch, lang_code)\n",
    "            all_preds += stringify(preds, False)\n",
    "            all_refs += stringify(batch['y'], True)\n",
    "        score = metric.compute(predictions = all_preds, references = all_refs)['score']\n",
    "    return score\n",
    "\n",
    "def test_loss(model, test_dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_dataloader.length):\n",
    "            batch = test_dataloader.sample_batch()\n",
    "            loss += model.forward_train(batch).loss\n",
    "    return loss/test_dataloader.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f6abff-1697-4ad1-be66-3b4ec6ea1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_size = 16\n",
    "# with open('de_dataset_test_full_'+str(checkpoint_size)+'.pkl', 'rb') as handle:\n",
    "#     de_test = pickle.load(handle)\n",
    "    \n",
    "# with open('cs_dataset_test_full_'+str(checkpoint_size)+'.pkl', 'rb') as handle:\n",
    "#     cs_test = pickle.load(handle)\n",
    "    \n",
    "# with open('cs_dataset_train_full_'+str(checkpoint_size)+'.pkl', 'rb') as handle:\n",
    "#     cs_train = pickle.load(handle)\n",
    "# with open('de_dataset_train_full_'+str(checkpoint_size)+'.pkl', 'rb') as handle:\n",
    "#     de_train = pickle.load(handle)\n",
    "\n",
    "# with open('./MFEA/data/cs_finetune.pkl', 'rb') as handle:\n",
    "#     cs_train = pickle.load(handle)\n",
    "# with open('./MFEA/data/de_finetune.pkl', 'rb') as handle:\n",
    "#     de_train = pickle.load(handle)\n",
    "\n",
    "with open('./train_data/de_test.pkl', 'rb') as handle:\n",
    "    de_test = pickle.load(handle)\n",
    "    \n",
    "with open('./train_data/cs_test.pkl', 'rb') as handle:\n",
    "    cs_test = pickle.load(handle)\n",
    "    \n",
    "with open('./train_data/cs_train.pkl', 'rb') as handle:\n",
    "    cs_train = pickle.load(handle)\n",
    "with open('./train_data/de_train.pkl', 'rb') as handle:\n",
    "    de_train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c878f50-ba52-4744-abd0-c8017bcfbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_test_dataloader = Custom_Dataloader(cs_test, 64)\n",
    "de_test_dataloader = Custom_Dataloader(de_test, 64)\n",
    "\n",
    "cs_train_dataloader = Custom_Dataloader(cs_train, 128)\n",
    "de_train_dataloader = Custom_Dataloader(de_train, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d650e24-974d-4797-86dc-288801e262e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load('./MFEA/models/base.pth'))\n",
    "model = model.cuda()\n",
    "model.update_backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a05853-5e85-4086-bb91-0eb971b1fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./MFEA/results/MT/Test_Run2/mask_checkpoint.pkl', 'rb') as f:\n",
    "    masks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc9440f-b52d-467a-ac82-a065113f7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b4b914-81e0-4a5d-945d-fafda4368b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_selected_models = [0, 1, 2, 3, 4, 6, 10, 11, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163bc19d-23e0-49f2-a79e-a93d689de157",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_selected_models = [0, 1, 2, 3, 4, 5, 6, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7acfbdde-a52e-4f59-a58e-8b163c69f9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [21.68546485900879, 627631104]),\n",
       " (1, [1.4215970039367676, 859735040]),\n",
       " (2, [6.353278923034668, 726033408]),\n",
       " (3, [11.179492092132568, 689091584]),\n",
       " (4, [8.54193468093872, 708367360]),\n",
       " (6, [14.507681369781494, 660734976]),\n",
       " (10, [5.093519449234009, 742331392]),\n",
       " (11, [2.751480221748352, 763823104]),\n",
       " (18, [2.1428685188293457, 781595648])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, masks[1][i]['objs_T1']) for i in range(0, 20) if i in cs_selected_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46791ea-1006-4993-872f-097aa5a0ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [21.964793968200684, 626664448]),\n",
       " (1, [1.6490003705024718, 858719232]),\n",
       " (2, [14.56126823425293, 659530752]),\n",
       " (3, [8.766735458374024, 705111040]),\n",
       " (4, [10.607507133483887, 683234304]),\n",
       " (5, [1.865936553478241, 810816512]),\n",
       " (6, [3.129116940498352, 761234432]),\n",
       " (8, [1.7327796578407288, 833205248]),\n",
       " (9, [4.683143568038941, 737731584])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, masks[2][i]['objs_T2']) for i in range(0, 20) if i in de_selected_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10c72e45-8488-4771-88f0-daaae3d3db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.revert_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4524f3ef-4447-4949-9447-cda0fac8fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in model.return_model_state():\n",
    "#     print(key, model.return_model_state()[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd19952-0b52-4a7f-befd-1882fa5e3adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483902464"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_active_params(model.return_model_state()) - (128112 * 1024 * 3) - (1026 * 1024 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08e6641f-e59c-4979-b431-685fa08035a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1845.94140625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((483902464*32) / (1024*8))/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ed5fe1-bc78-48c0-8cb0-eb06acc341a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(879566848)\n",
      "tensor(352321536)\n",
      "67584\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  0 , Model Size:  231969792\n",
      "\n",
      " Starting Loss:  1.8520716428756714 , Lang Code:  cs , Model:  0\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.455\n",
      " Best Averaged Loss:  1.8515033721923828 , Lang Code:  cs , Model:  0\n",
      "\n",
      " Starting Loss:  1.8515034914016724 , Lang Code:  cs , Model:  0\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 3.142\n",
      " Best Averaged Loss:  1.8501688241958618 , Lang Code:  cs , Model:  0\n",
      "\n",
      " Starting Loss:  1.8501687049865723 , Lang Code:  cs , Model:  0\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 3.658\n",
      " Best Averaged Loss:  1.847960352897644 , Lang Code:  cs , Model:  0\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  1 , Model Size:  464073728\n",
      "\n",
      " Starting Loss:  1.2566149234771729 , Lang Code:  cs , Model:  1\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 1.054\n",
      " Best Averaged Loss:  1.2566672563552856 , Lang Code:  cs , Model:  1\n",
      "\n",
      " Starting Loss:  1.2566674947738647 , Lang Code:  cs , Model:  1\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 0.453\n",
      " Best Averaged Loss:  1.2567379474639893 , Lang Code:  cs , Model:  1\n",
      "\n",
      " Starting Loss:  1.2567379474639893 , Lang Code:  cs , Model:  1\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 2.060\n",
      " Best Averaged Loss:  1.2568258047103882 , Lang Code:  cs , Model:  1\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  2 , Model Size:  330372096\n",
      "\n",
      " Starting Loss:  1.5506811141967773 , Lang Code:  cs , Model:  2\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 1.682\n",
      " Best Averaged Loss:  1.5497193336486816 , Lang Code:  cs , Model:  2\n",
      "\n",
      " Starting Loss:  1.5497195720672607 , Lang Code:  cs , Model:  2\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 0.464\n",
      " Best Averaged Loss:  1.5472602844238281 , Lang Code:  cs , Model:  2\n",
      "\n",
      " Starting Loss:  1.5472602844238281 , Lang Code:  cs , Model:  2\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 1.288\n",
      " Best Averaged Loss:  1.5440033674240112 , Lang Code:  cs , Model:  2\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  3 , Model Size:  293430272\n",
      "\n",
      " Starting Loss:  1.4273346662521362 , Lang Code:  cs , Model:  3\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.633\n",
      " Best Averaged Loss:  1.4267197847366333 , Lang Code:  cs , Model:  3\n",
      "\n",
      " Starting Loss:  1.4267195463180542 , Lang Code:  cs , Model:  3\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 2.394\n",
      " Best Averaged Loss:  1.42515230178833 , Lang Code:  cs , Model:  3\n",
      "\n",
      " Starting Loss:  1.4251519441604614 , Lang Code:  cs , Model:  3\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 0.208\n",
      " Best Averaged Loss:  1.4227769374847412 , Lang Code:  cs , Model:  3\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  4 , Model Size:  312706048\n",
      "\n",
      " Starting Loss:  1.443218469619751 , Lang Code:  cs , Model:  4\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.395\n",
      " Best Averaged Loss:  1.442630410194397 , Lang Code:  cs , Model:  4\n",
      "\n",
      " Starting Loss:  1.4426302909851074 , Lang Code:  cs , Model:  4\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 0.698\n",
      " Best Averaged Loss:  1.441191554069519 , Lang Code:  cs , Model:  4\n",
      "\n",
      " Starting Loss:  1.441191554069519 , Lang Code:  cs , Model:  4\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 0.593\n",
      " Best Averaged Loss:  1.4392213821411133 , Lang Code:  cs , Model:  4\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  6 , Model Size:  265073664\n",
      "\n",
      " Starting Loss:  1.7602287530899048 , Lang Code:  cs , Model:  6\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.300\n",
      " Best Averaged Loss:  1.7596290111541748 , Lang Code:  cs , Model:  6\n",
      "\n",
      " Starting Loss:  1.7596288919448853 , Lang Code:  cs , Model:  6\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 1.615\n",
      " Best Averaged Loss:  1.7580249309539795 , Lang Code:  cs , Model:  6\n",
      "\n",
      " Starting Loss:  1.7580244541168213 , Lang Code:  cs , Model:  6\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 0.487\n",
      " Best Averaged Loss:  1.7557533979415894 , Lang Code:  cs , Model:  6\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  10 , Model Size:  346670080\n",
      "\n",
      " Starting Loss:  1.4667946100234985 , Lang Code:  cs , Model:  10\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.635\n",
      " Best Averaged Loss:  1.4662387371063232 , Lang Code:  cs , Model:  10\n",
      "\n",
      " Starting Loss:  1.4662388563156128 , Lang Code:  cs , Model:  10\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 0.445\n",
      " Best Averaged Loss:  1.4647481441497803 , Lang Code:  cs , Model:  10\n",
      "\n",
      " Starting Loss:  1.4647483825683594 , Lang Code:  cs , Model:  10\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 2.745\n",
      " Best Averaged Loss:  1.4629377126693726 , Lang Code:  cs , Model:  10\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  11 , Model Size:  368161792\n",
      "\n",
      " Starting Loss:  1.401081919670105 , Lang Code:  cs , Model:  11\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.506\n",
      " Best Averaged Loss:  1.4002282619476318 , Lang Code:  cs , Model:  11\n",
      "\n",
      " Starting Loss:  1.4002279043197632 , Lang Code:  cs , Model:  11\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 1.796\n",
      " Best Averaged Loss:  1.397960901260376 , Lang Code:  cs , Model:  11\n",
      "\n",
      " Starting Loss:  1.3979605436325073 , Lang Code:  cs , Model:  11\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 1.644\n",
      " Best Averaged Loss:  1.3956059217453003 , Lang Code:  cs , Model:  11\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  cs , Candidate:  18 , Model Size:  385934336\n",
      "\n",
      " Starting Loss:  1.3491753339767456 , Lang Code:  cs , Model:  18\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.816\n",
      " Best Averaged Loss:  1.3486206531524658 , Lang Code:  cs , Model:  18\n",
      "\n",
      " Starting Loss:  1.3486205339431763 , Lang Code:  cs , Model:  18\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 0.517\n",
      " Best Averaged Loss:  1.3469789028167725 , Lang Code:  cs , Model:  18\n",
      "\n",
      " Starting Loss:  1.3469789028167725 , Lang Code:  cs , Model:  18\n",
      "Epoch 2.000\tBatch: 1199.000, Loss: 2.090\n",
      " Best Averaged Loss:  1.3451515436172485 , Lang Code:  cs , Model:  18\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Lang Code:  de , Candidate:  0 , Model Size:  231003136\n",
      "\n",
      " Starting Loss:  1.8992136716842651 , Lang Code:  de , Model:  0\n",
      "Epoch 0.000\tBatch: 1199.000, Loss: 0.717\n",
      " Best Averaged Loss:  1.898467779159546 , Lang Code:  de , Model:  0\n",
      "\n",
      " Starting Loss:  1.8984678983688354 , Lang Code:  de , Model:  0\n",
      "Epoch 1.000\tBatch: 1199.000, Loss: 0.740\n",
      " Best Averaged Loss:  1.8968684673309326 , Lang Code:  de , Model:  0\n",
      "\n",
      " Starting Loss:  1.8968688249588013 , Lang Code:  de , Model:  0\n",
      "Epoch 2.000\tBatch: 12.000, Loss: 2.231"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_74972/2964142123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Lang Code: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m', Candidate: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m', Model Size: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_active_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_model_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m128112\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1024\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1026\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1024\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 train_loop(model, \n\u001b[0m\u001b[0;32m     44\u001b[0m                            \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                            \u001b[0mmask_sizing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_74972/3019375583.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(model, mask, mask_sizing, lang1_train_dataloader, lang1_test_dataloader, epochs, lang_code, model_idx, steps)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n Starting Loss: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m', Lang Code: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m', Model: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         train(model, \n\u001b[0m\u001b[0;32m     40\u001b[0m               \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_sizing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m               \u001b[0mlang1_train_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_74972/3019375583.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, mask, mask_sizing, lang1_train_dataloader, optim, steps, epoch)\u001b[0m\n\u001b[0;32m     81\u001b[0m         print('\\rEpoch {:.3f}\\tBatch: {:.3f}, Loss: {:.3f}'.format(epoch, \n\u001b[0;32m     82\u001b[0m                                                                    \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                                                                    loss.detach().item()), \n\u001b[0m\u001b[0;32m     84\u001b[0m               end=\"\")\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m120\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask_sizing = size_mask(model.return_model_state())\n",
    "\n",
    "for skill_factor in masks:\n",
    "    for i, candidate in enumerate(masks[skill_factor]):\n",
    "        \n",
    "        \n",
    "        mask = candidate['rnvec']\n",
    "        model.apply_mask(mask, mask_sizing)\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        if skill_factor == 1:\n",
    "            if i in cs_selected_models:\n",
    "                lang_code = 'cs'\n",
    "                if os.path.isfile('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'):\n",
    "                    print(\"Starting from Checkpoint\")\n",
    "                    model.load_state_dict(torch.load('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'))\n",
    "\n",
    "                    for name, param in model.named_parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "                print('----------')\n",
    "                print('Lang Code: ', lang_code, ', Candidate: ', str(i), ', Model Size: ', str(count_active_params(model.return_model_state()) - (128112 * 1024 * 3) - (1026 * 1024 * 2)))\n",
    "                train_loop(model, \n",
    "                           mask,\n",
    "                           mask_sizing,\n",
    "                          cs_train_dataloader, \n",
    "                          cs_test_dataloader, \n",
    "                          3, lang_code, i)\n",
    "        else:\n",
    "            if i in de_selected_models:\n",
    "                lang_code = 'de'\n",
    "                if os.path.isfile('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'):\n",
    "                    print(\"Starting from Checkpoint\")\n",
    "                    model.load_state_dict(torch.load('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'))\n",
    "\n",
    "                    for name, param in model.named_parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "                print('----------')\n",
    "                print('Lang Code: ', lang_code, ', Candidate: ', str(i), ', Model Size: ', str(count_active_params(model.return_model_state()) - (128112 * 1024 * 3) - (1026 * 1024 * 2)))\n",
    "                train_loop(model, \n",
    "                           mask,\n",
    "                           mask_sizing,\n",
    "                          de_train_dataloader, \n",
    "                          de_test_dataloader, \n",
    "                          3, lang_code, i)            \n",
    "\n",
    "        model.revert_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522c8a6f-a3ec-478c-bd58-bf97b556d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = datasets.load_metric('sacrebleu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c99028b-aa95-499d-950e-7e343781c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.revert_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eca02c27-ca2a-4dcf-ae7b-7bff0f6bf9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.658459055339222 1845.94140625\n"
     ]
    }
   ],
   "source": [
    "score = test_BLEU(model, cs_test_dataloader, metric, 'cs')\n",
    "mem = count_active_params(model.return_model_state()) - (128112 * 1024 * 3) - (1026 * 1024 * 2)\n",
    "mem = ((mem*32) / (1024*8))/1024\n",
    "\n",
    "print(score, mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea2c538f-e8ad-4113-9876-9c77386e3003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.571392328999416 1845.94140625\n"
     ]
    }
   ],
   "source": [
    "score = test_BLEU(model, de_test_dataloader, metric, 'de')\n",
    "mem = count_active_params(model.return_model_state()) - (128112 * 1024 * 3) - (1026 * 1024 * 2)\n",
    "mem = ((mem*32) / (1024*8))/1024\n",
    "\n",
    "print(score, mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68ced357-a002-4e20-804f-dad1c7236f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(879566848)\n",
      "tensor(352321536)\n",
      "67584\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  23.854002187191682 , Lang Code:  cs , Candidate:  0 , Model Size:  884.89453125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  32.22747264598261 , Lang Code:  cs , Candidate:  1 , Model Size:  1770.30078125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  26.898700478784054 , Lang Code:  cs , Candidate:  2 , Model Size:  1260.26953125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  31.91246970741459 , Lang Code:  cs , Candidate:  3 , Model Size:  1119.34765625\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  32.1336120762841 , Lang Code:  cs , Candidate:  4 , Model Size:  1192.87890625\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  24.685699230399294 , Lang Code:  cs , Candidate:  6 , Model Size:  1011.17578125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  28.457910455709765 , Lang Code:  cs , Candidate:  10 , Model Size:  1322.44140625\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  30.152389736476827 , Lang Code:  cs , Candidate:  11 , Model Size:  1404.42578125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  30.321455461369865 , Lang Code:  cs , Candidate:  18 , Model Size:  1472.22265625\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  21.29226708687752 , Lang Code:  de , Candidate:  0 , Model Size:  881.20703125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  23.99233217870648 , Lang Code:  de , Candidate:  1 , Model Size:  1766.42578125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  22.21373807430573 , Lang Code:  de , Candidate:  2 , Model Size:  1006.58203125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  23.333850317280728 , Lang Code:  de , Candidate:  3 , Model Size:  1180.45703125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  22.738922753998107 , Lang Code:  de , Candidate:  4 , Model Size:  1097.00390625\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  24.064876510828327 , Lang Code:  de , Candidate:  5 , Model Size:  1583.69140625\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  23.896947833654597 , Lang Code:  de , Candidate:  6 , Model Size:  1394.55078125\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  24.331468331673822 , Lang Code:  de , Candidate:  8 , Model Size:  1669.09765625\n",
      "Starting from Checkpoint\n",
      "----------\n",
      "Score:  24.131666338433572 , Lang Code:  de , Candidate:  9 , Model Size:  1304.89453125\n"
     ]
    }
   ],
   "source": [
    "mask_sizing = size_mask(model.return_model_state())\n",
    "\n",
    "results = {}\n",
    "\n",
    "for skill_factor in masks:\n",
    "    for i, candidate in enumerate(masks[skill_factor]):\n",
    "        \n",
    "        mask = candidate['rnvec']\n",
    "        model.apply_mask(mask, mask_sizing)\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        if skill_factor == 1:\n",
    "            if i in cs_selected_models:\n",
    "                lang_code = 'cs'\n",
    "                if os.path.isfile('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'):\n",
    "                    print(\"Starting from Checkpoint\")\n",
    "                    model.load_state_dict(torch.load('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'))\n",
    "\n",
    "                    for name, param in model.named_parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "                print('----------')\n",
    "                task_name = 'cs_only'\n",
    "                score = test_BLEU(model, cs_test_dataloader, metric, 'cs')\n",
    "                mem = count_active_params(model.return_model_state()) - (128112 * 1024 * 3) - (1026 * 1024 * 2)\n",
    "                mem = ((mem*32) / (1024*8))/1024\n",
    "                print('Score: ', score, ', Lang Code: ', lang_code, ', Candidate: ', str(i), ', Model Size: ', mem)\n",
    "                if task_name not in results:\n",
    "                    results.update({task_name:[(score, mem)]})\n",
    "                else:\n",
    "                    curr = results[task_name]\n",
    "                    curr.append((score, mem))\n",
    "                    results.update({task_name:curr})\n",
    "        else:\n",
    "            if i in de_selected_models:\n",
    "                lang_code = 'de'\n",
    "                if os.path.isfile('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'):\n",
    "                    print(\"Starting from Checkpoint\")\n",
    "                    model.load_state_dict(torch.load('./MFEA/final_models/'+lang_code+'_'+str(i)+'.pth'))\n",
    "\n",
    "                    for name, param in model.named_parameters():\n",
    "                        param.requires_grad = True\n",
    "                task_name = 'de_only'\n",
    "                print('----------')\n",
    "                score = test_BLEU(model, de_test_dataloader, metric, 'de')\n",
    "                mem = count_active_params(model.return_model_state()) - (128112 * 1024 * 3) - (1026 * 1024 * 2)\n",
    "                mem = ((mem*32) / (1024*8))/1024\n",
    "                print('Score: ', score, ', Lang Code: ', lang_code, ', Candidate: ', str(i), ', Model Size: ', mem)\n",
    "                if task_name not in results:\n",
    "                    results.update({task_name:[(score, mem)]})\n",
    "                else:\n",
    "                    curr = results[task_name]\n",
    "                    curr.append((score, mem))\n",
    "                    results.update({task_name:curr})\n",
    "        model.revert_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8371e72-8957-472b-badd-f2e110648cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cs_only': [(23.854002187191682, 884.89453125),\n",
       "  (32.22747264598261, 1770.30078125),\n",
       "  (26.898700478784054, 1260.26953125),\n",
       "  (31.91246970741459, 1119.34765625),\n",
       "  (32.1336120762841, 1192.87890625),\n",
       "  (24.685699230399294, 1011.17578125),\n",
       "  (28.457910455709765, 1322.44140625),\n",
       "  (30.152389736476827, 1404.42578125),\n",
       "  (30.321455461369865, 1472.22265625)],\n",
       " 'de_only': [(21.29226708687752, 881.20703125),\n",
       "  (23.99233217870648, 1766.42578125),\n",
       "  (22.21373807430573, 1006.58203125),\n",
       "  (23.333850317280728, 1180.45703125),\n",
       "  (22.738922753998107, 1097.00390625),\n",
       "  (24.064876510828327, 1583.69140625),\n",
       "  (23.896947833654597, 1394.55078125),\n",
       "  (24.331468331673822, 1669.09765625),\n",
       "  (24.131666338433572, 1304.89453125)]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7dd33be-8fd6-49d6-866b-84e0dae2f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = results['cs_only']\n",
    "cs = [i for i in cs if i[1] not in [1119.34765625, 1192.87890625]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d412015-9d0b-495b-bad5-2d62f1e58d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23.854002187191682, 884.89453125),\n",
       " (32.22747264598261, 1770.30078125),\n",
       " (26.898700478784054, 1260.26953125),\n",
       " (24.685699230399294, 1011.17578125),\n",
       " (28.457910455709765, 1322.44140625),\n",
       " (30.152389736476827, 1404.42578125),\n",
       " (30.321455461369865, 1472.22265625)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0644b13a-abe9-4619-b157-5790ace72c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "de = results['de_only']\n",
    "de = [i for i in de if i[1] not in [1766.42578125, 1304.89453125]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6b094a3-f468-44cf-89c2-a3f743f4d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {'cs_only':cs, 'de_only':de}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db341e26-13a2-4f21-aa24-5cfdce831653",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./MFEA/results/MT/Test_Run2/finetuned_results.pkl', 'wb') as f:\n",
    "    pickle.dump(final_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
